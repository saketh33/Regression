{"cells":[{"metadata":{"_uuid":"7857fdad608085d67ad0e41535215d7c6df5b3ff"},"cell_type":"markdown","source":"**1. Introduction: (#1)**\n\n**2. Loading Data and Explanation of Features: (#2)**\n\n**3. Exploratory Data Analysis (EDA): (#3)**\n\n**4. Applying Regression Models: (#4)**\n\n**5. CONCLUSION: (#5)**"},{"metadata":{"_uuid":"e1bd15f5c177fccc5edcc48be2a520e0c9dfe839"},"cell_type":"markdown","source":"<a id=\"1\"></a> \n**1. Introduction**\n\nHello everyone!  In this kernel we will be working on Vehicle dataset from cardekho Dataset . This dataset contains information about used cars listed on www.cardekho.com. We are going to use for finding predictions of price with the use of regression models.\n\nThe datasets consist of several  independent variables  include:\n\n* Car_Name\n* Year\n* Selling_Price\n* Present_Price\n* Kms_Driven\n* Fuel_Type\n* Seller_Type\n* Transmission\n* Owner\n\nWe are going to use some of the variables which we need for regression models."},{"metadata":{"_uuid":"1af1fcde537f1d969cd5df08bc5d21efeca3c013"},"cell_type":"markdown","source":"<a id=\"2\"></a> \n**2. Loading Data and Explanation of Features**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#seaborn\nimport seaborn as sns\n# matplotlib\nimport matplotlib.pyplot as plt\n# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"../input/car data.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e1b0525bcfe9d4e3ef1e8502bfb17e47e960d7b"},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dcde60708e46dc5f8c27c0fb2a9bdbddb24037cf"},"cell_type":"code","source":"data.isna().any()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a7fdb274c3abfe6f53bcdfaa9177ff958bc4fb2"},"cell_type":"markdown","source":"Looks like our data is complete one. There is no NaN values and also feature's types are proper."},{"metadata":{"_uuid":"fc41a944da7bcdc7fbe06e2caf1ed9f3032c2c0e"},"cell_type":"markdown","source":"Lets see value counts of the features which are the object type."},{"metadata":{"trusted":true,"_uuid":"b3e2a0c73fafea134e554f9f325e6aa17d7f4817"},"cell_type":"code","source":"print(data.Fuel_Type.value_counts(),\"\\n\")\nprint(data.Seller_Type.value_counts(),\"\\n\")\nprint(data.Transmission.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cd67aaf963ca836c637b4d838141fa3bf30bf8e"},"cell_type":"markdown","source":"I am going to chance these object values to numerical values to make it proper for regression models."},{"metadata":{"trusted":true,"_uuid":"81a1adf2f6f932bb0c348db878c0379beb3498a1"},"cell_type":"code","source":"#Fuel_Type ==> 1 = Petrol , 0 = Diesel , 2 = CNG\n#Seller_Type ==> 1 = Manual , 0 = Automatic \n#Seller_Type ==> 1 = Dealer , 0 = Individual\n\ndata.Fuel_Type.replace(regex={\"Petrol\":\"0\",\"Diesel\":\"1\",\"CNG\":\"2\"},inplace=True)\ndata.Seller_Type.replace(regex={\"Dealer\":\"0\",\"Individual\":\"1\"},inplace=True)\ndata.Transmission.replace(regex={\"Manual\":\"0\",\"Automatic\":\"1\"},inplace=True)\ndata[[\"Fuel_Type\",\"Seller_Type\",\"Transmission\"]]=data[[\"Fuel_Type\",\"Seller_Type\",\"Transmission\"]].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7bd6324b3f46579cb0468de753a40b99bf85f8e"},"cell_type":"markdown","source":"<a id=\"3\"></a> \n**3. Exploratory Data Analysis (EDA)**"},{"metadata":{"_uuid":"8b341d3f9ad73a6940d2356be699e5c3f87eaae6"},"cell_type":"markdown","source":"Before applying regression models, lets look at the features and also relationship with each other by visually."},{"metadata":{"trusted":true,"_uuid":"22222cec651743849fea4644bd7c9c6dbba7a741"},"cell_type":"code","source":"sns.pairplot(data,diag_kind=\"kde\", diag_kws=dict(shade=True, bw=.05, vertical=False))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"505025abae837bca46bfcf672cee8d226d12dcdd","scrolled":true},"cell_type":"code","source":"from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(16,9))\nax  = fig.gca(projection = \"3d\")\n\nplot =  ax.scatter(data[\"Year\"],\n           data[\"Present_Price\"],\n           data[\"Kms_Driven\"],\n           linewidth=1,edgecolor =\"k\",\n           c=data[\"Selling_Price\"],s=100,cmap=\"hot\")\n\nax.set_xlabel(\"Year\")\nax.set_ylabel(\"Present_Price\")\nax.set_zlabel(\"Kms_Driven\")\n\nlab = fig.colorbar(plot,shrink=.5,aspect=5)\nlab.set_label(\"Selling_Price\",fontsize = 15)\n\nplt.title(\"3D plot for Year, Present price and Kms driven\",color=\"red\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f451f74f7a788b758ed0909b7924aafb7becfc0e"},"cell_type":"markdown","source":"If we 3D plot critic features that effect selling price, we can see most of the cars accumulate around after 2010 year, low present price and low kms driven. Now its time to apply regression models."},{"metadata":{"_uuid":"220c047cd6cc2cdb93a8f008dc35d5c7a8f1d9f2"},"cell_type":"markdown","source":"<a id=\"4\"></a> \n**4. Applying Regression Models**"},{"metadata":{"_uuid":"f8d95d68a1b5fc2a3e3a915285cd7d2af29b4524"},"cell_type":"markdown","source":"Firstly lets separate Selling price from the data and drop unnecessary features."},{"metadata":{"trusted":true,"_uuid":"412010396af79d65558c32dc28bc55a0331208dd"},"cell_type":"code","source":"y=data.Selling_Price\nx=data.drop([\"Selling_Price\",\"Car_Name\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc78c6d1d6fe8b2d304bd53a46ae3f4a07bbbbbf"},"cell_type":"markdown","source":"Spliting data to train and test sizes."},{"metadata":{"trusted":true,"_uuid":"3d928f6902df504aff06059c16495c250b9cd307"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\nprint(\"x train: \",x_train.shape)\nprint(\"x test: \",x_test.shape)\nprint(\"y train: \",y_train.shape)\nprint(\"y test: \",y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04b90f4ff3d95f10b84b98ec7ebcaeeedebdd076"},"cell_type":"markdown","source":"Secondly we are going to load libraries that we need calculate scores fo regression models. Than apply function which fit the models, get the scores and plot our predictions ."},{"metadata":{"trusted":true,"_uuid":"ac845417833a945ee31f153fad4eb8cfcf07e0da"},"cell_type":"code","source":"from sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c472dd35b9878cee60f619d0d6c66723e47e67a8"},"cell_type":"code","source":"cv=5 # CV value\nr_2 = [] # List for r 2 score\nCV = [] # list for CV scores mean\n\n# Main function for models\ndef model(algorithm,x_train_,y_train_,x_test_,y_test_): \n    algorithm.fit(x_train_,y_train_)\n    predicts=algorithm.predict(x_test_)\n    prediction=pd.DataFrame(predicts)\n    R_2=r2_score(y_test_,prediction)\n    cross_val=cross_val_score(algorithm,x_train_,y_train_,cv=cv)\n    \n    # Appending results to Lists \n    r_2.append(R_2)\n    CV.append(cross_val.mean())\n    \n    # Printing results  \n    print(algorithm,\"\\n\") \n    print(\"r_2 score :\",R_2,\"\\n\")\n    print(\"CV scores:\",cross_val,\"\\n\")\n    print(\"CV scores mean:\",cross_val.mean())\n    \n    # Plot for prediction vs originals\n    test_index=y_test_.reset_index()[\"Selling_Price\"]\n    ax=test_index.plot(label=\"originals\",figsize=(12,6),linewidth=2,color=\"r\")\n    ax=prediction[0].plot(label = \"predictions\",figsize=(12,6),linewidth=2,color=\"g\")\n    plt.legend(loc='upper right')\n    plt.title(\"ORIGINALS VS PREDICTIONS\")\n    plt.xlabel(\"index\")\n    plt.ylabel(\"values\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"405f2e1bfcff1440de78d1ff6b1e0bebfe9ec736"},"cell_type":"markdown","source":"**1. Linear Regression**"},{"metadata":{"trusted":true,"_uuid":"7dc10b52c67313d5189daef2726ceb25ad936656"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nmodel(lr,x_train,y_train,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba1baad70a97970e7e960ee447ea430c21382659"},"cell_type":"markdown","source":"**2. Lasso **"},{"metadata":{"_uuid":"ae9220d99da64ee4a0b2719003a0f009dec8a4f1"},"cell_type":"markdown","source":"Before applying Lasso model, I am going to assign a alpha range that effect model and choose the best estimator for model.   "},{"metadata":{"trusted":true,"_uuid":"f33ae508163ad604ca45818814c6409e48236295"},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV\n\nalphas = np.logspace(-3,3,num=14) # range for alpha\n\ngrid = GridSearchCV(estimator=Lasso(), param_grid=dict(alpha=alphas))\ngrid.fit(x_train, y_train)\n\nprint(grid.best_score_)\nprint(grid.best_estimator_.alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a12f09fb04a21b7e205b2918fb33e5f9ea048f7a"},"cell_type":"code","source":"ls = Lasso(alpha = grid.best_estimator_.alpha, normalize = True) # applied the best estimator\nmodel(ls,x_train,y_train,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6369852bed4b83e64967c834727215e6f9d7478"},"cell_type":"markdown","source":"**3. Ridge**"},{"metadata":{"_uuid":"d2e4d460881c11d5abbf56bb495eeb2e54c4543c"},"cell_type":"markdown","source":"We are going to do same operation for Ridge"},{"metadata":{"trusted":true,"_uuid":"0469d935fa77420125226a473f6c24b98dc144a1"},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nalphas = np.logspace(-3,3,num=14) # range for alpha\n\ngrid2 = GridSearchCV(estimator=Ridge(), param_grid=dict(alpha=alphas)) \ngrid2.fit(x_train, y_train)\n\nprint(grid2.best_score_)\nprint(grid2.best_estimator_.alpha)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"416f47712f57e654101b2be9858ad2fd8f6169d6"},"cell_type":"code","source":"ridge = Ridge(alpha = 0.01, normalize = True) # applied the best estimator\nmodel(ridge,x_train,y_train,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f608b12cf49e5166cdef44c678da0cc3799ba52c"},"cell_type":"markdown","source":"**4. Decision Tree Regressor**"},{"metadata":{"trusted":true,"_uuid":"5dca00f03ec301adb9f8c910df03e3a7f95e02df"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndtr = DecisionTreeRegressor()\nmodel(dtr,x_train,y_train,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc7df43b57bdb382f33a1bdfc3e766b49b8814b4"},"cell_type":"markdown","source":"**5. Random Forest Regressor**"},{"metadata":{"trusted":true,"_uuid":"150c2e86d0637816624eaf3535cce19df9ded8c5"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 100, random_state = 42)\nmodel(rf,x_train,y_train,x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"051af5b80b8769881b5a81edb8ffffa4a359ffca"},"cell_type":"markdown","source":"Lets see the results together in dataframe"},{"metadata":{"trusted":true,"_uuid":"b8c6b89e45493320fd1e310ed36f6c3f239089b8"},"cell_type":"code","source":"Model = [\"LinearRegression\",\"Lasso\",\"Ridge\",\"DecisionTreeRegressor\",\"RandomForestRegressor\"]\nresults=pd.DataFrame({'Model': Model,'R Squared': r_2,'CV score mean': CV})\nresults","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f4251741f8f2d69b62c57580140a7f43e34b1a1"},"cell_type":"markdown","source":"<a id=\"5\"></a> \n**5. CONCLUSION**"},{"metadata":{"_uuid":"fe62aa8c339e890e01306f49a143d6106def7a6e"},"cell_type":"markdown","source":"We applied couple of regression models on dataset.  From the final dataframe, it gives opinion  about the score of models  and also the  plots help us to understand which models is more succesful.\n\n* If you like it, thank you for you upvotes.\n* If you have any question, I will happy to hear it\n\nAlso look for https://www.kaggle.com/kanncaa1/machine-learning-tutorial-for-beginners for Machine Learning"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}